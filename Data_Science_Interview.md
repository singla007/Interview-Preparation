[LDA vs PDA](https://www.youtube.com/watch?v=M4HpyJHPYBY) <br/>
[Mean, Variance and Standard Deviation](https://www.geeksforgeeks.org/mathematics-mean-variance-and-standard-deviation/)  <br/>
[Random Forest](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ) <br/>
[Gradient Boost](https://www.youtube.com/watch?v=3CC4N4z3GJc) <br/>
[Descision Tree](https://www.youtube.com/watch?v=_L39rN6gz7Y) <br/>
[Naive Bayes Classifier](https://www.youtube.com/watch?v=O2L2Uv9pdDA) <br/>
[Precision Recall F1_score](https://medium.com/@mahesh.chavan1997/what-is-precision-recall-f1-score-b65b1965804c) <br/>
[Elbow method for optimal value of k in kmeans](https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/) <br/>
[Python OOPS concepts](https://www.pythontutorial.net/python-oop/) <br/>
[Statistical Tests](https://www.youtube.com/watch?v=I10q6fjPxJ0) <br/>
[Optimizers in Deep Learning Algorithms](https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-on-deep-learning-optimizers/) <br/>
[Optimizers in Deep Learning Algorithms -2](https://medium.com/analytics-vidhya/this-blog-post-aims-at-explaining-the-behavior-of-different-algorithms-for-optimizing-gradient-46159a97a8c1) <br/>
[Word2Vec - CBOW and Skip-gram](https://www.youtube.com/watch?v=CsgiVnW401c) <br/>
[Word2Vec - CBOW and Skip-gram Notebook-1](https://neptune.ai/blog/word-embeddings-guide) <br/>
[Word2Vec - CBOW and Skip-gram Notebook-2](https://www.kaggle.com/code/alincijov/nlp-starter-continuous-bag-of-words-cbow) <br/>
[Word Embeddings](https://www.youtube.com/watch?v=mWvnlVw_LiY&list=PL75e0qA87dlG-za8eLI6t0_Pbxafk-cxb&index=5)  <br/>
[tfidf](https://www.youtube.com/watch?v=D2V1okCEsiE)




    Recall: Measures the proportion of relevant documents that are retrieved by the system out of all relevant documents in the dataset. High recall means that the system is able to retrieve most of the relevant documents. It's calculated as: Recall=True PositivesTrue Positives+False NegativesRecall=True Positives+False NegativesTrue Positives​.

    Precision: Measures the proportion of retrieved documents that are actually relevant out of all retrieved documents. High precision means that the system returns mostly relevant documents. It's calculated as: Precision=True PositivesTrue Positives+False PositivesPrecision=True Positives+False PositivesTrue Positives​.

